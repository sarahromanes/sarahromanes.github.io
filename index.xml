<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Sarah Romanes on Sarah Romanes</title>
    <link>/</link>
    <description>Recent content in Sarah Romanes on Sarah Romanes</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Wed, 20 Apr 2016 00:00:00 +1000</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Diagonal Discriminant Analysis with Feature Selection for High Dimensional Data</title>
      <link>/publication/multida/</link>
      <pubDate>Mon, 01 Jul 2019 00:00:00 +1000</pubDate>
      
      <guid>/publication/multida/</guid>
      <description></description>
    </item>
    
    <item>
      <title>My first gganimate - exploring concepts from first year linear modelling!</title>
      <link>/post/gganimate/</link>
      <pubDate>Tue, 28 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/gganimate/</guid>
      <description>&lt;p&gt;Have you ever had one of those moments whilst teaching where the content blows your mind? Today, whilst teaching MATH1005 at the University of Sydney, that exact thing happened to me.&lt;/p&gt;
&lt;p&gt;This weeks content was focused on teaching the students the introductions to linear modelling. A very strightforward topic, and one ususally understood well by first years. However, a twist in our teaching style left me with such an appreciation for the simpler explanations in statistics.&lt;/p&gt;
&lt;div id=&#34;linear-modelling---through-calculus&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Linear modelling - through calculus&lt;/h2&gt;
&lt;p&gt;Throwing back to 6 years ago when I was a first year, and even back to a year ago when I first taught this course, linear regression was taught in a very standard way.&lt;/p&gt;
&lt;p&gt;If I have some continuous bivariate data, and the relationship between the two variables looks linear upon inspection, how can one fit a line which is ‘optimal’? The standard way of answering this question is to treat the problem as a mathematical one, using &lt;strong&gt;calculus&lt;/strong&gt; to find the slope and intercept that minimise the sum of squares between the fitted line and the observed responses. See &lt;a href=&#34;https://math.stackexchange.com/a/63301&#34;&gt;&lt;strong&gt;here&lt;/strong&gt;&lt;/a&gt; for one of the many examples of this on StackExchange.&lt;/p&gt;
&lt;p&gt;This usually is very easy to understand by first years, and seemed the simplest possible way of explanation I could concieve. But then came along another explanation…&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-sd-line&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The SD Line&lt;/h2&gt;
&lt;p&gt;Imagine you are trying to find the best line to fit the data, without any knowledge of calculus. How do you do it? An intuitive way might be to connect the point of averages &lt;span class=&#34;math inline&#34;&gt;\((\bar{x}, \bar{y})\)&lt;/span&gt; to &lt;span class=&#34;math inline&#34;&gt;\((\bar{x} + \text{SD}_x, \bar{y} + \text{SD}_y)\)&lt;/span&gt;. This is described in detail by Freedman, Pisani, and Purves in their book, &lt;a href=&#34;https://www.amazon.com/Statistics-Fourth-David-Freedman-ebook/dp/B00SLB5Q72&#34;&gt;&lt;strong&gt;Statistics&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/sdline.jpg&#34; width=&#34;700px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Applying this to simulated data, we can visualise the SD line as follows:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)
library(dplyr)
library(magrittr)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gen.y &amp;lt;- function(x, rho) {
  y &amp;lt;- rnorm(length(x)) 
  x.perp &amp;lt;- residuals(lm(y ~ x))
  rho * sd(x.perp) * x + x.perp * sd(x) * sqrt(1 - rho^2)
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x &amp;lt;- 1:50
y &amp;lt;- gen.y(x, 0.5)

dat &amp;lt;- data.frame(x=x, y=y)

p.sd &amp;lt;- ggplot(dat %&amp;gt;% mutate(slope.sd=sd(y)/sd(x), 
                        icept.sd= mean(y)- (sd(y)/sd(x))*mean(x)),
                        aes(x, y)) + 
        geom_point() + 
        geom_abline(aes(intercept=icept.sd, slope=slope.sd), col=&amp;quot;red&amp;quot;)+
        geom_vline(xintercept = mean(x)+sd(x))+
        geom_vline(xintercept = mean(x)-sd(x))+
        geom_point(aes(x=mean(x), y=mean(y)), colour=&amp;quot;dodgerblue&amp;quot;, size=5)+
        ggtitle(&amp;quot;SD Line for simulated linear data with r = 0.5&amp;quot;)
        
p.sd&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-08-28-gganimate_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We have highlighted the point of averages &lt;span class=&#34;math inline&#34;&gt;\((\bar{x}, \bar{y})\)&lt;/span&gt;, and 1 SD on either side of this point. We can see the SD line does a pretty decent job of describing the linear relationship! But alas! Let’s look closely at the extremes. Towards the RHS, the SD line &lt;strong&gt;overestimates&lt;/strong&gt; the y response, and towards the LHS, it &lt;strong&gt;underestimates&lt;/strong&gt; the values. How can we fix this?&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;a-fix-the-regression&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;A fix? The regression&lt;/h2&gt;
&lt;p&gt;The regression line is very similar to the SD line, with a slight change in how it is defined. The regression line is defined as the line connecting &lt;span class=&#34;math inline&#34;&gt;\((\bar{x}, \bar{y})\)&lt;/span&gt; to &lt;span class=&#34;math inline&#34;&gt;\((\bar{x} + \text{SD}_x, \bar{y} + r\text{SD}_y)\)&lt;/span&gt;. See the change? We have incorporated information about how the points &lt;strong&gt;cluster&lt;/strong&gt; around the line. As &lt;span class=&#34;math inline&#34;&gt;\(r\)&lt;/span&gt; is in magnitude between &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;, the only effect it can possbly have is to &lt;strong&gt;dampen&lt;/strong&gt; the gradient! As such, this will push our line down towards the positive extreme, and push the line up towards the negative extreme.&lt;/p&gt;
&lt;p&gt;You can show that the equation of this line matches that derived by least squares estimation! Hoorah! How amazing is that???! Or is that only me…&lt;/p&gt;
&lt;p&gt;See the effect on our simulated data below, taking advantage of the &lt;code&gt;geom_smooth()&lt;/code&gt; function in &lt;code&gt;ggplot2&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p.r &amp;lt;- p.sd + geom_smooth(method=&amp;#39;lm&amp;#39;,formula=y~x) + ggtitle(&amp;quot;SD and Regression lines for simulated data, r=0.5&amp;quot;)
p.r&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-08-28-gganimate_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We can compare the two lines as follows&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/compare.jpg&#34; width=&#34;700px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;And you can experiment with an app online by Berkeley &lt;a href=&#34;https://www.stat.berkeley.edu/~stark/Java/Html/Correlation.htm&#34;&gt;&lt;strong&gt;here&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;gganimate---a-success&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;code&gt;gganimate&lt;/code&gt; - a success!&lt;/h2&gt;
&lt;p&gt;A cool feature about the regression line is that as &lt;span class=&#34;math inline&#34;&gt;\(r \rightarrow \pm 1\)&lt;/span&gt;, it approaches the SD line! So I thought I would devise my first &lt;code&gt;gganimate&lt;/code&gt; plot highlighting this. Feedback regarding the code is much appreciated!&lt;/p&gt;
&lt;p&gt;If you don’t have &lt;code&gt;gganimate&lt;/code&gt;, you can download from here. Note, this is an updated version &lt;em&gt;not on CRAN&lt;/em&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# install.packages(&amp;#39;devtools&amp;#39;)
devtools::install_github(&amp;#39;thomasp85/gganimate&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(gganimate)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;First, I set up the plot without the animation layers. It looks like a bit of a mess with out the frames! The red line is the SD line, and the blue lines are the regression lines.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x &amp;lt;- 0:50
r &amp;lt;- seq(0, 1, by=0.05)

y.vals &amp;lt;- unlist(purrr::map(r, ~gen.y(x, .)))
x.vals &amp;lt;- rep(x, length(r))
r.vals &amp;lt;- rep(r, each=length(x))


data &amp;lt;- data.frame(x.vals=x.vals, y.vals=y.vals, r.vals=r.vals)
head(data)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   x.vals     y.vals r.vals
## 1      0 -17.071776      0
## 2      1   7.112183      0
## 3      2  10.129332      0
## 4      3 -25.638644      0
## 5      4  26.779453      0
## 6      5   7.190922      0&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p.set &amp;lt;- ggplot( data %&amp;gt;% group_by(r.vals) %&amp;gt;% mutate(slope.sd=sd(y.vals)/sd(x.vals), 
                                     icept.sd= mean(y.vals)- (sd(y.vals)/sd(x.vals))*mean(x.vals),
                                     slope.r=r.vals*sd(y.vals)/sd(x.vals),
                                     icept.r= mean(y.vals)- (r.vals*sd(y.vals)/sd(x.vals))*mean(x.vals))
             , aes(x.vals, y.vals)) + 
  geom_point() + 
  geom_abline(aes(intercept=icept.sd, slope=slope.sd), col=&amp;quot;red&amp;quot;) +
  geom_abline(aes(intercept=icept.r, slope=slope.r), col=&amp;quot;blue&amp;quot;)


p.set&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-08-28-gganimate_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Now, we add in the animation layers. And voila! We have an animation!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p.ani  &amp;lt;- p.set + labs(title = &amp;#39;Correlation Coefficient =  {round(frame_time, 2)}&amp;#39;, x = &amp;#39;x&amp;#39;, y = &amp;#39;y&amp;#39;) +
  transition_time(r.vals) +
  ease_aes(&amp;#39;linear&amp;#39;)

p.ani&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-08-28-gganimate_files/figure-html/unnamed-chunk-8-1.gif&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>An argument for eating that pizza whilst on vacation - exploring the sugrrants package</title>
      <link>/post/calendar-plots/</link>
      <pubDate>Wed, 08 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/calendar-plots/</guid>
      <description>&lt;div id=&#34;ah-back-to-reality&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Ah, back to reality!&lt;/h1&gt;
&lt;p&gt;Last month, I was fortunate enough to be able to travel away from the cold Sydney winter over to Central and North America for a holiday and also to present my work on multiDA at JSM in Vancouver. Whilst at JSM, I was able to hear &lt;a href=&#34;https://twitter.com/earowang&#34;&gt;&lt;strong&gt;Earo&lt;/strong&gt;&lt;/a&gt; present her work (along with &lt;a href=&#34;https://twitter.com/visnut&#34;&gt;&lt;strong&gt;Di&lt;/strong&gt;&lt;/a&gt; and &lt;a href=&#34;https://twitter.com/robjhyndman&#34;&gt;&lt;strong&gt;Rob&lt;/strong&gt;&lt;/a&gt;) on making calendar plots in R, using data from pedestrian traffic in Melbourne (see more &lt;a href=&#34;https://github.com/earowang/sugrrants&#34;&gt;&lt;strong&gt;here&lt;/strong&gt;&lt;/a&gt;). I was super impressed by my work, and on my flight home I realised I could also have a crack at using the package by analysing my own step count data. I felt like I had walked a lot more whilst I was travelling - would the visualisation agree?&lt;/p&gt;
&lt;center&gt;
&lt;p&gt;&lt;img src=&#34;/img/cruise.jpg&#34; width=&#34;700px&#34; /&gt;&lt;/p&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;div id=&#34;step-count-visualisation-from-my-iphone-with-sugrrants&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Step count visualisation from my iPhone with &lt;code&gt;sugrrants&lt;/code&gt;&lt;/h1&gt;
&lt;div id=&#34;export-data-off-the-iphone&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;1) Export data off the iPhone&lt;/h3&gt;
&lt;p&gt;I use the &lt;a href=&#34;http://quantifiedself.com/qs-access-app/&#34;&gt;&lt;strong&gt;QS Access App&lt;/strong&gt;&lt;/a&gt; to export data from Apple Health into an easy to load &lt;code&gt;.csv&lt;/code&gt; format for analysis. If you have a Samsung like I did before (you’ll be able to notice on the resultant calendar plot the day and time I switched over), it is &lt;strong&gt;much&lt;/strong&gt; more difficult to export data from Samsung health. I had planned to combine that data with my iPhone data to no avail, the steps are long and require you to download old SDK’s from github and enable developer mode (see more &lt;a href=&#34;https://android.stackexchange.com/questions/117112/is-it-possible-to-export-the-s-health-data-from-a-samsung-s6-into-a-usable-data&#34;&gt;&lt;strong&gt;here&lt;/strong&gt;&lt;/a&gt;). In the end, the data I managed to get off completely struck off the date component, and it seemed like my Samsung was counting fake steps when I was sleeping every night at around 3-4am. Rubbish data.&lt;/p&gt;
&lt;center&gt;
&lt;p&gt;&lt;img src=&#34;/img/garbage.gif&#34; height=&#34;200&#34;&gt;&lt;/p&gt;
&lt;/center&gt;
&lt;p&gt;Onwards and upwards with the iPhone data!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;some-data-cleaning&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;2) Some data cleaning&lt;/h3&gt;
&lt;p&gt;Before we go any further, we are going to have to load some libraries into R. To save time, you could simply load the &lt;code&gt;tidyverse&lt;/code&gt; package for all requirements to be loaded. Specifically, we will be using the &lt;code&gt;dplyr&lt;/code&gt; and &lt;code&gt;lubridate&lt;/code&gt; packages for this step. You will also need the &lt;code&gt;magrittr&lt;/code&gt; package for the pipe function (optional).&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;steps_export.csv&lt;/code&gt; file contains &lt;strong&gt;three&lt;/strong&gt; variables - the start date time for when data was collected, the finish date time, and the number of steps in that period. The data is grouped by the hour, which is very handy. We first rename the column names for ease of analysis, and use the &lt;code&gt;lubridate&lt;/code&gt; package to convert our date into something sensible that R can understand (it is initially read in as a factor). We then use the &lt;code&gt;dplyr&lt;/code&gt; package to create new Time and Date columns, which is needed by the &lt;code&gt;sugrrants&lt;/code&gt; package later on.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(lubridate)
library(dplyr)
library(stringr)
library(magrittr)

data &amp;lt;- read.csv(&amp;quot;steps_export.csv&amp;quot;)
colnames(data) &amp;lt;- c(&amp;quot;Start&amp;quot;, &amp;quot;Finish&amp;quot;, &amp;quot;Count&amp;quot;)
data &amp;lt;- mutate_at(data, vars(-Count), funs(dmy_hm(.)))
data &amp;lt;- data %&amp;gt;% select (-c(Start)) #drop `Start` variable - only care about counts at the end of the hour.

data &amp;lt;- mutate(data, Time=hour(Finish))
data &amp;lt;- mutate(data, Date=date(Finish))

head(data)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                Finish     Count Time       Date
## 1 2018-06-17 17:00:00 347.00000   17 2018-06-17
## 2 2018-06-17 18:00:00  22.00000   18 2018-06-17
## 3 2018-06-17 19:00:00 114.17046   19 2018-06-17
## 4 2018-06-17 20:00:00  20.82954   20 2018-06-17
## 5 2018-06-17 21:00:00   0.00000   21 2018-06-17
## 6 2018-06-17 22:00:00   0.00000   22 2018-06-17&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;generate-an-intial-calendar-plot&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;3) Generate an intial calendar plot&lt;/h3&gt;
&lt;p&gt;To generate our calendar plot, we use the &lt;code&gt;sugrrants&lt;/code&gt; package to transform our data frame into a frame_calendar format, which allows `&lt;code&gt;ggplot2&lt;/code&gt; to effectively plot the data in a calendar format. More details about the usage of the package can be found &lt;a href=&#34;https://pkg.earo.me/sugrrants/articles/frame-calendar.html&#34;&gt;&lt;strong&gt;here&lt;/strong&gt;&lt;/a&gt;, and the nifty tricks behind it &lt;a href=&#34;https://robjhyndman.com/papers/calendar-vis.pdf&#34;&gt;&lt;strong&gt;here&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(sugrrants)

data_cal &amp;lt;- data %&amp;gt;% frame_calendar(
  x = Time, y = Count, date = Date, calendar = &amp;quot;monthly&amp;quot;
)

p &amp;lt;- data_cal %&amp;gt;%
  ggplot(aes(x = .Time, y = .Count, group = Date)) +
  geom_line() +
  theme(legend.position = &amp;quot;bottom&amp;quot;)

p&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-08-08-exploring-step-count-data-with-sugrrants_files/figure-html/first%20plot-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The initial plot sort of resembles a calendar. However, we can make it look much more calendar like with the use of the &lt;code&gt;prettify&lt;/code&gt; function, and voila! A calendar plot!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;prettify(p, label.padding = unit(0.08, &amp;quot;lines&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-08-08-exploring-step-count-data-with-sugrrants_files/figure-html/prettyfy-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;a-slight-nuisance---time-zones&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;4) A slight nuisance - time zones!&lt;/h3&gt;
&lt;p&gt;If you look closely, even though you can see the general pattern that whilst I am away (9th July to 6th Aug) I am more active than the preceding weeks, the timing of my steps is all off due to me hopping around different time zones, and the data when exported being set to Sydney (GMT + 10) time! Oh dear!&lt;/p&gt;
&lt;center&gt;
&lt;p&gt;&lt;img src=&#34;/img/travels.jpg&#34; width=&#34;700px&#34; /&gt;&lt;/p&gt;
&lt;/center&gt;
&lt;p&gt;Although I visited many different timezones at different times of the day (eg, on 24th July I went from GMT -6, to -4, to -5), I decided for days that I was in multiple time zones to pick one that described the day the best. For the month of July, I decided on the following, with a similar concept for August as well.&lt;/p&gt;
&lt;center&gt;
&lt;p&gt;&lt;img src=&#34;/img/calendar.jpg&#34; width=&#34;700px&#34; /&gt;&lt;/p&gt;
&lt;/center&gt;
&lt;p&gt;So how do I account for this?&lt;/p&gt;
&lt;p&gt;I decided I would shift my whole data set from key travel dates forward and back all at once, and then for subsequent travel dates I would keep on shifting forwards and back until all dates had been accounted for. I won’t put in all the R code, but I include the code I used to make the first shift to the time zone in Costa Rica (-16 hrs from Sydney). Dates that overlapped with Sydney after being shifted back were deleted so that the steps in Sydney time would be plotted, with Costa Rica steps starting at midnight on 9th July.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# First shift - all data post 9 July to CR time zone, -16hrs #

inds_shift &amp;lt;- which(data$Date &amp;gt;= as.Date(&amp;quot;2018-07-09&amp;quot;))
data_shift &amp;lt;- data %&amp;gt;% filter(Date &amp;gt;= as.Date(&amp;quot;2018-07-09&amp;quot;))

data_shift &amp;lt;- mutate_at(data_shift, vars(Finish), funs(.-hours(x=16)))
data_shift &amp;lt;- mutate(data_shift, Date=date(Finish))
data_shift &amp;lt;- mutate(data_shift, Time=hour(Finish))
head(data_shift)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                Finish Count Time       Date
## 1 2018-07-08 08:00:00     0    8 2018-07-08
## 2 2018-07-08 09:00:00     0    9 2018-07-08
## 3 2018-07-08 10:00:00     0   10 2018-07-08
## 4 2018-07-08 11:00:00     0   11 2018-07-08
## 5 2018-07-08 12:00:00     0   12 2018-07-08
## 6 2018-07-08 13:00:00     0   13 2018-07-08&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;del &amp;lt;- which(data_shift$Date==as.Date(&amp;quot;2018-07-09&amp;quot;))
inds_shift &amp;lt;- inds_shift[-del]

data[inds_shift,] &amp;lt;- data_shift[-del,]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Implementing these shifts, we have a more reasonable looking calendar plot. Woohoo!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data_cal &amp;lt;- data %&amp;gt;% frame_calendar(
  x = Time, y = Count, date = Date, calendar = &amp;quot;monthly&amp;quot;
)

p &amp;lt;- data_cal %&amp;gt;%
  ggplot(aes(x = .Time, y = .Count, group = Date)) +
  geom_line() +
  theme(legend.position = &amp;quot;bottom&amp;quot;)
prettify(p, label.padding = unit(0.08, &amp;quot;lines&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-08-08-exploring-step-count-data-with-sugrrants_files/figure-html/new%20plot-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;add-in-some-colour&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;5) Add in some colour!&lt;/h3&gt;
&lt;p&gt;The last step I did was to colour the dates by what area/timezone I was in, by adding in a column called &lt;code&gt;Region&lt;/code&gt; which I used in the plotting step to add a colour element. I also cleaned up and removed data from the 5th of August - I left SFO at 11pm on 4th August local time and arrived 6.30am in Sydney on 6th August - so data on that day did not make sense in either timezone.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p &amp;lt;- data_cal %&amp;gt;%
  ggplot(aes(x = .Time, y = .Count, group = Date, colour=Region)) +
  geom_line() +
  theme(legend.position = &amp;quot;bottom&amp;quot;)
prettify(p, label.padding = unit(0.08, &amp;quot;lines&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-08-08-exploring-step-count-data-with-sugrrants_files/figure-html/color-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;What do you think? My steps definitely went up when I was away! Can you spot the time when I walked 8km in 30 degree heat from Wicker Park to downtown in Chicago? Or the day where it rained in Tortuguero all day in Costa Rica and the only walking I did was to see the turtle laying eggs at 8pm?&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;an-alternative-view---a-cumulative-step-plot&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;6) An alternative view - a cumulative step plot!&lt;/h3&gt;
&lt;p&gt;I also thought I would try a cumulative sum step plot. Using a &lt;strong&gt;for loop&lt;/strong&gt;, yes, a loop (I know some people will already dismiss me at this point, but I love for loops - sue me!), I calculate the cumulative sum over entries that share the same date.&lt;/p&gt;
&lt;center&gt;
&lt;iframe src=&#34;https://giphy.com/embed/JeYi8mZamkZ1e&#34; width=&#34;480&#34; height=&#34;270&#34; frameBorder=&#34;0&#34; class=&#34;giphy-embed&#34; allowFullScreen&gt;
&lt;/iframe&gt;
&lt;p&gt;
&lt;a href=&#34;https://giphy.com/gifs/suits-usa-JeYi8mZamkZ1e&#34;&gt;via GIPHY&lt;/a&gt;
&lt;/p&gt;
&lt;/center&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data &amp;lt;- data %&amp;gt;% mutate(Cumulative_Count=Count)
for(i in 1:nrow(data)){
  if(i == 1){
    data$Cumulative_Count[i]=data$Count[i]
  }else if(data$Date[i]!=data$Date[i-1]){
    data$Cumulative_Count[i]=data$Count[i]
  }else{
    data$Cumulative_Count[i]=data$Count[i]+data$Cumulative_Count[i-1]
  }
}

head(data)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                Finish     Count Time       Date Region Cumulative_Count
## 1 2018-06-17 17:00:00 347.00000   17 2018-06-17 Sydney         347.0000
## 2 2018-06-17 18:00:00  22.00000   18 2018-06-17 Sydney         369.0000
## 3 2018-06-17 19:00:00 114.17046   19 2018-06-17 Sydney         483.1705
## 4 2018-06-17 20:00:00  20.82954   20 2018-06-17 Sydney         504.0000
## 5 2018-06-17 21:00:00   0.00000   21 2018-06-17 Sydney         504.0000
## 6 2018-06-17 22:00:00   0.00000   22 2018-06-17 Sydney         504.0000&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data_cal &amp;lt;- data %&amp;gt;% frame_calendar(
  x = Time, y = Cumulative_Count, date = Date, calendar = &amp;quot;monthly&amp;quot;
)

p &amp;lt;- data_cal %&amp;gt;%
  ggplot(aes(x = .Time, y = .Cumulative_Count, group = Date, colour=Region)) +
  geom_line() +
  theme(legend.position = &amp;quot;bottom&amp;quot;)
prettify(p, label.padding = unit(0.08, &amp;quot;lines&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-08-08-exploring-step-count-data-with-sugrrants_files/figure-html/cumulative-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Something looks pretty funny around the transition between Costa Rica and Sydney time zones. Most likely I’ve made some errors when accounting for the two timezones. However, that shall be a post for another day! Right now, time for some tea… and pizza&lt;/p&gt;
&lt;center&gt;
&lt;h2&gt;
Take home message - eat that pizza when travelling - you’ll be back to a sloth when at home!
&lt;/h2&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;p&gt;&lt;img src=&#34;/img/sloth.jpg&#34; width=&#34;700px&#34; /&gt;&lt;/p&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>R-Ladies Sydney Launch!</title>
      <link>/post/r-ladies-sydney-launch/</link>
      <pubDate>Fri, 22 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/r-ladies-sydney-launch/</guid>
      <description>&lt;link href=&#34;/rmarkdown-libs/font-awesome/css/fontawesome-all.min.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;link href=&#34;/rmarkdown-libs/font-awesome-animation/font-awesome-animation-emi.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;/rmarkdown-libs/fontawesome/js/fontawesome-all.min.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;the-launch&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;The Launch!&lt;/h1&gt;
&lt;p&gt;Wow, what a launch! Thank you so much &lt;a href=&#34;https://twitter.com/JenRichmondPhD&#34;&gt;&lt;strong&gt;Jen&lt;/strong&gt;&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/djnavarro&#34;&gt;&lt;strong&gt;Dani&lt;/strong&gt;&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/StephdeSilva&#34;&gt;&lt;strong&gt;Steph&lt;/strong&gt;&lt;/a&gt;, and &lt;a href=&#34;https://twitter.com/williamslisaphd&#34;&gt;&lt;strong&gt;Lisa&lt;/strong&gt;&lt;/a&gt; for all your work setting up this launch! I can’t wait to see what the future events will hold! I was lucky enough to be able to give a lightening talk describing my R journey below - of which I have summarised for those who could not be there! You can also find the slides &lt;a href=&#34;https://sarahromanes.github.io/recent-talk&#34;&gt;&lt;strong&gt;here&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;center&gt;
&lt;p&gt;&lt;img src=&#34;/img/montage.jpg&#34; width=&#34;700px&#34; /&gt;&lt;/p&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;div id=&#34;my-long-journey-using-r---a-summary&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;My (long) journey using R - a summary!!&lt;/h1&gt;
&lt;p&gt;My background is in mathematical statistics, in which I was introduced to R during my BSc degree, and used it from first year all the way through to my honours year. R was introduced to me as a glorified calculator in first year, with it’s main purpose to do basic tests and calclate probabilities! In fact, now that I think about it, I didn’t even &lt;strong&gt;read in&lt;/strong&gt; data into R until my 2nd semester of 2nd year. Crazy!!!&lt;/p&gt;
&lt;div id=&#34;what-i-was-formally-taught-during-my-undergraduate-degree-in-r-2012---2015&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;What I was formally taught during my undergraduate degree in R (2012 - 2015)&lt;/h3&gt;
&lt;p&gt;&lt;i class=&#34;fas  fa-check &#34;&gt;&lt;/i&gt; Statistical modelling techniques&lt;/p&gt;
&lt;p&gt;&lt;i class=&#34;fas  fa-check &#34;&gt;&lt;/i&gt; … and through that, baseR (by experience).&lt;/p&gt;
&lt;p&gt;&lt;i class=&#34;fas  fa-check &#34;&gt;&lt;/i&gt; Basic report making via Sweave implementation&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;strong&gt;Essentially - a strong focus on Statistics, and less focus on Data Science! R was a means to the end.&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;what-i-was-not-formally-taught-during-my-undergraduate-degree&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;What I was NOT formally taught during my undergraduate degree&lt;/h3&gt;
&lt;p&gt;&lt;i class=&#34;fas  fa-times &#34;&gt;&lt;/i&gt; tidyverse, eg. &lt;code&gt;ggplot2&lt;/code&gt;, &lt;code&gt;dplyr&lt;/code&gt;, &lt;code&gt;purrr&lt;/code&gt; packages&lt;/p&gt;
&lt;p&gt;&lt;i class=&#34;fas  fa-times &#34;&gt;&lt;/i&gt; rmarkdown/ xaringan slides/ blogdown&lt;/p&gt;
&lt;p&gt;&lt;i class=&#34;fas  fa-times &#34;&gt;&lt;/i&gt; advanced R topics such as functions, object orientated programming, good programming practice&lt;/p&gt;
&lt;p&gt;&lt;i class=&#34;fas  fa-times &#34;&gt;&lt;/i&gt; package development&lt;/p&gt;
&lt;p&gt;&lt;i class=&#34;fas  fa-times &#34;&gt;&lt;/i&gt; git/ github/ version control&lt;/p&gt;
&lt;center&gt;
&lt;h2&gt;
So why am I telling you all of this?
&lt;/h2&gt;
&lt;/center&gt;
&lt;div id=&#34;everyone-still-has-something-to-learn-in-r-even-if-we-have-been-using-it-for-a-long-time&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;1) Everyone still has something to learn in R, even if we have been using it for a long time&lt;/h4&gt;
&lt;p&gt;Especially those of us who learnt R ‘formally’! For example, a lot of us are learning the &lt;code&gt;tidyverse&lt;/code&gt; along side you! If you ask us for how to do things, we might give you a long baseR solution…&lt;/p&gt;
&lt;center&gt;
&lt;p&gt;&lt;img src=&#34;/img/harder.jpg&#34; width=&#34;400px&#34; /&gt;&lt;/p&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;div id=&#34;learning-these-things-takes-time-and-patience-and-life-does-get-in-the-way&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;2) Learning these things takes time and patience, and life does get in the way!&lt;/h4&gt;
&lt;p&gt;I thought I would spend all my PhD reading textbooks and learning new R techiniques (see below). However research, admin, and teaching can get in the way!&lt;/p&gt;
&lt;center&gt;
&lt;p&gt;&lt;img src=&#34;/img/tenor.gif&#34; height=&#34;400&#34;&gt;&lt;/p&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;h2&gt;
My tips on learning &lt;span&gt;&amp;lt;i class=&#34;fab  fa-r-project fa-2x faa-pulse animated &#34;&amp;gt;&amp;lt;/i&amp;gt;&lt;/span&gt;
&lt;/h2&gt;
&lt;/center&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;My best improvements in R came from having clear motivations for WHY I was learning new skills&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;I learned &lt;code&gt;ggplot2&lt;/code&gt; to make better data vis for presentations/publications/ packages&lt;/li&gt;
&lt;li&gt;I learned how to develop packages to complement my research and to also improve workflow&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Learn from examples! Eg, this presentation was based off Alison Hill’s R Ladies talk about blogdown! Work smart, not hard.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Having a mentor is extremely useful. I found my coding to improve drastically after my honours year as I had great guidance from an expert (my supervisor).&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Bayesian hypothesis tests with diffuse priors: Can we have our cake and eat it too?</title>
      <link>/publication/bayesian-testing/</link>
      <pubDate>Wed, 25 Oct 2017 00:00:00 +1100</pubDate>
      
      <guid>/publication/bayesian-testing/</guid>
      <description></description>
    </item>
    
    <item>
      <title>R-Ladies Lightning Talk</title>
      <link>/talk/r-ladies-talk/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +1100</pubDate>
      
      <guid>/talk/r-ladies-talk/</guid>
      <description></description>
    </item>
    
    <item>
      <title>R-Ladies Sydney - Introduction to Machine Learning - Part 1</title>
      <link>/talk/r-ladies-ws-1/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +1100</pubDate>
      
      <guid>/talk/r-ladies-ws-1/</guid>
      <description></description>
    </item>
    
    <item>
      <title>R-Ladies Sydney - Introduction to Machine Learning - Part 2</title>
      <link>/talk/r-ladies-ws-2/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +1100</pubDate>
      
      <guid>/talk/r-ladies-ws-2/</guid>
      <description></description>
    </item>
    
    <item>
      <title>genDA: Using Variational Approximations to efficiently build a Generalised Discriminant Analysis Algorithm </title>
      <link>/talk/acems-talk/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +1100</pubDate>
      
      <guid>/talk/acems-talk/</guid>
      <description></description>
    </item>
    
    <item>
      <title>multiDA and genDA: Discriminant Analysis Methods for Large Scale and Complex Datasets</title>
      <link>/talk/user2019/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +1100</pubDate>
      
      <guid>/talk/user2019/</guid>
      <description></description>
    </item>
    
    <item>
      <title>multiDA: Prediction of Melanoma Prognosis Class using a Multiclass Discriminant Analysis classifier with Feature Selection </title>
      <link>/talk/jsm-talk/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +1100</pubDate>
      
      <guid>/talk/jsm-talk/</guid>
      <description></description>
    </item>
    
    <item>
      <title>genDA</title>
      <link>/packages/jenga/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +1000</pubDate>
      
      <guid>/packages/jenga/</guid>
      <description>&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.&lt;/p&gt;

&lt;p&gt;Nullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.&lt;/p&gt;

&lt;p&gt;Cras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.&lt;/p&gt;

&lt;p&gt;Suspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.&lt;/p&gt;

&lt;p&gt;Aliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>multiDA</title>
      <link>/packages/multida/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +1000</pubDate>
      
      <guid>/packages/multida/</guid>
      <description>&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.&lt;/p&gt;

&lt;p&gt;Nullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.&lt;/p&gt;

&lt;p&gt;Cras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.&lt;/p&gt;

&lt;p&gt;Suspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.&lt;/p&gt;

&lt;p&gt;Aliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
